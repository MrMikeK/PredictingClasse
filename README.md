This presentation will show you how I developed a model of prediction. Velloso, Gellersen, Ugulino and Fuks (see citation below) generously allowed myself and many others to use data from their Human Activity Recognition (HAR) project, where they connected sensors to people and equipment as the people did a biceps curl.  The volunteers did some correctly and some that corresponded to 4 different types of errors, totaling 5 classes.  I set up a framework to use the information given to predict future classes.  The real-life implication is that people can wear a fitbit and know whether or not they do this exercise correctly, and if not how they might correct their error(s).

Once I ensure I'm in the right directory with the right files, I pare down the HAR dataframe so as not to include empty columns, columns full of NAs and columns that refer specifically to the original experiment (such as ID numbers of the particular individuals).  Then, I conduct 7 random forest trainings, each with different variables.

The first random forest seems to do a pretty good job (86% accuracy) predicting classe by itself, but to improve the accuracy I combine all 7 models and make a data frame of the results.  I run a function that takes the most common response for each row and this becomes the row's prediction.  All predictions go in a one-column data frame.  I include code for making random samples on which to test (this cross-validation improves on the preexisting cross-validation that is automatically built into random forests in R.  I include the results - 99.8% accuracy across 7 samples of 100 total classes.  I also discuss the OOB accuracy prediction.
